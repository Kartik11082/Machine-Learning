{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj5WkzT_3JFd",
        "outputId": "dda0c55e-b534-44c9-bada-7685116100ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ILKuyXwoyv",
        "outputId": "79ff15d2-11a6-4c8f-b35d-d718f8294575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Num GPUs Available: 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageFile\n",
        "from tensorflow.keras import layers, models  # type: ignore\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # type: ignore\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_corrupted_images(base_dir):\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                try:\n",
        "                    filepath = os.path.join(root, file)\n",
        "                    img = Image.open(filepath)\n",
        "                    img.verify()  # This will raise an exception for corrupt files\n",
        "                except Exception as e:\n",
        "                    print(f\"Removing corrupt image: {filepath} ({e})\")\n",
        "                    os.remove(filepath)\n",
        "                    count += 1\n",
        "    print(f\"Removed {count} corrupted image(s)\")"
      ],
      "metadata": {
        "id": "r6hP57Ecw8eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this once before training\n",
        "remove_corrupted_images(\"Mushrooms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgwkSkQhw-CP",
        "outputId": "e59aea35-315e-4fe7-9dcd-22ee6fe8c793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 0 corrupted image(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1.0 / 255,\n",
        "#     validation_split=0.2,\n",
        "#     rotation_range=20,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "# )"
      ],
      "metadata": {
        "id": "qkDQu3ipw_Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1.0 / 255,\n",
        "#     validation_split=0.2,\n",
        "#     rotation_range=30,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.3,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode=\"nearest\",\n",
        "# )\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.4,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode=\"nearest\",\n",
        ")"
      ],
      "metadata": {
        "id": "QBZa18SzH14s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHzm_Dr6H3sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Mushrooms\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\",\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Mushrooms\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIiq-5-2xBcL",
        "outputId": "a97aaf27-3cbb-454b-ec2f-903c264c3c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5375 images belonging to 9 classes.\n",
            "Found 1339 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights=\"imagenet\"\n",
        ")"
      ],
      "metadata": {
        "id": "6ZDseAJAxDoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unfreezed_layers = -100\n",
        "for layer in base_model.layers[:unfreezed_layers]:  # freeze early 90% layers\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model.layers[unfreezed_layers:]:  # unfreeze deeper high-level layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# base_model = tf.keras.applications.EfficientNetB0(\n",
        "#     input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights=\"imagenet\"\n",
        "# )"
      ],
      "metadata": {
        "id": "nRbpo5Y-xEzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze base\n",
        "base_model.trainable = True\n",
        "\n",
        "\n",
        "# model = models.Sequential(\n",
        "#     [\n",
        "#         base_model,\n",
        "#         layers.GlobalAveragePooling2D(),\n",
        "#         layers.Dense(128, activation=\"relu\"),\n",
        "#         layers.Dropout(0.5),\n",
        "#         layers.Dense(9, activation=\"softmax\"),  # 9 classes\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# model = models.Sequential(\n",
        "#     [\n",
        "#         base_model,\n",
        "#         layers.GlobalAveragePooling2D(),\n",
        "#         layers.Dense(256, activation=\"relu\"),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.Dropout(0.3),\n",
        "#         layers.Dense(128, activation=\"relu\"),\n",
        "#         layers.Dropout(0.3),\n",
        "#         layers.Dense(9, activation=\"softmax\"),  # 9 classes\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(9, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "HDmPStq4xGvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "SRNe-vTvJDMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, validation_data=val_generator, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdJteNgQ1k6S",
        "outputId": "d343709a-5b34-4cb6-d76e-96ea97d893b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1065s\u001b[0m 6s/step - accuracy: 0.2762 - loss: 2.6557 - val_accuracy: 0.2405 - val_loss: 13.2560\n",
            "Epoch 2/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 809ms/step - accuracy: 0.4814 - loss: 1.6378 - val_accuracy: 0.2226 - val_loss: 4.5677\n",
            "Epoch 3/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 810ms/step - accuracy: 0.5895 - loss: 1.2382 - val_accuracy: 0.3167 - val_loss: 6.2529\n",
            "Epoch 4/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 811ms/step - accuracy: 0.6607 - loss: 1.0327 - val_accuracy: 0.2957 - val_loss: 8.3757\n",
            "Epoch 5/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 816ms/step - accuracy: 0.7057 - loss: 0.8886 - val_accuracy: 0.3607 - val_loss: 4.6150\n",
            "Epoch 6/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 808ms/step - accuracy: 0.7349 - loss: 0.7942 - val_accuracy: 0.4145 - val_loss: 4.4257\n",
            "Epoch 7/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 893ms/step - accuracy: 0.7522 - loss: 0.7308 - val_accuracy: 0.3167 - val_loss: 5.3798\n",
            "Epoch 8/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 807ms/step - accuracy: 0.7640 - loss: 0.6883 - val_accuracy: 0.2957 - val_loss: 5.9786\n",
            "Epoch 9/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 806ms/step - accuracy: 0.7692 - loss: 0.6793 - val_accuracy: 0.3488 - val_loss: 4.1335\n",
            "Epoch 10/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 806ms/step - accuracy: 0.8002 - loss: 0.6057 - val_accuracy: 0.3854 - val_loss: 4.1986\n",
            "Epoch 11/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 820ms/step - accuracy: 0.8059 - loss: 0.5922 - val_accuracy: 0.4780 - val_loss: 2.5979\n",
            "Epoch 12/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 810ms/step - accuracy: 0.8114 - loss: 0.5742 - val_accuracy: 0.4630 - val_loss: 2.7668\n",
            "Epoch 13/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 806ms/step - accuracy: 0.8234 - loss: 0.5315 - val_accuracy: 0.3794 - val_loss: 3.6350\n",
            "Epoch 14/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 804ms/step - accuracy: 0.8092 - loss: 0.5572 - val_accuracy: 0.3876 - val_loss: 4.3866\n",
            "Epoch 15/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 894ms/step - accuracy: 0.8333 - loss: 0.5142 - val_accuracy: 0.3667 - val_loss: 4.1779\n",
            "Epoch 16/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 813ms/step - accuracy: 0.8162 - loss: 0.5555 - val_accuracy: 0.4339 - val_loss: 3.1727\n",
            "Epoch 17/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 822ms/step - accuracy: 0.8444 - loss: 0.4707 - val_accuracy: 0.3981 - val_loss: 3.1185\n",
            "Epoch 18/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 813ms/step - accuracy: 0.8327 - loss: 0.4995 - val_accuracy: 0.5848 - val_loss: 1.8834\n",
            "Epoch 19/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 816ms/step - accuracy: 0.8389 - loss: 0.4598 - val_accuracy: 0.4981 - val_loss: 2.2907\n",
            "Epoch 20/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 807ms/step - accuracy: 0.8365 - loss: 0.4940 - val_accuracy: 0.4892 - val_loss: 2.6900\n",
            "Epoch 21/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 811ms/step - accuracy: 0.8449 - loss: 0.4621 - val_accuracy: 0.4093 - val_loss: 3.4125\n",
            "Epoch 22/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 811ms/step - accuracy: 0.8514 - loss: 0.4523 - val_accuracy: 0.3114 - val_loss: 5.0839\n",
            "Epoch 23/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 892ms/step - accuracy: 0.8604 - loss: 0.4303 - val_accuracy: 0.3592 - val_loss: 4.5647\n",
            "Epoch 24/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 809ms/step - accuracy: 0.8660 - loss: 0.4189 - val_accuracy: 0.4488 - val_loss: 2.2828\n",
            "Epoch 25/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 813ms/step - accuracy: 0.8679 - loss: 0.4009 - val_accuracy: 0.4414 - val_loss: 2.8177\n",
            "Epoch 26/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 812ms/step - accuracy: 0.8623 - loss: 0.4111 - val_accuracy: 0.3525 - val_loss: 4.2130\n",
            "Epoch 27/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 812ms/step - accuracy: 0.8704 - loss: 0.3884 - val_accuracy: 0.3032 - val_loss: 4.5105\n",
            "Epoch 28/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 826ms/step - accuracy: 0.8635 - loss: 0.4148 - val_accuracy: 0.2584 - val_loss: 5.0327\n",
            "Epoch 29/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 808ms/step - accuracy: 0.8662 - loss: 0.3928 - val_accuracy: 0.3181 - val_loss: 5.3515\n",
            "Epoch 30/30\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 808ms/step - accuracy: 0.8766 - loss: 0.3624 - val_accuracy: 0.4235 - val_loss: 3.8029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "dZ8DSmG51mgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "a3JGJuuhJTIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(1e-5),  # Lower LR\n",
        "#     loss=\"categorical_crossentropy\",\n",
        "#     metrics=[\"accuracy\"],\n",
        "# )"
      ],
      "metadata": {
        "id": "D7lnqiLT1oA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor=\"val_loss\", factor=0.5, patience=3, verbose=1, min_lr=1e-7\n",
        "# )\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)"
      ],
      "metadata": {
        "id": "y-9hrDbB1pcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[lr_schedule],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5uvltTO1qr2",
        "outputId": "e5c5309b-1247-4e2b-b42c-67b6ef709138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 930ms/step - accuracy: 0.9056 - loss: 0.2964 - val_accuracy: 0.5721 - val_loss: 2.0890 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 827ms/step - accuracy: 0.9274 - loss: 0.2308 - val_accuracy: 0.6154 - val_loss: 1.7279 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 911ms/step - accuracy: 0.9395 - loss: 0.1996 - val_accuracy: 0.6804 - val_loss: 1.3281 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 824ms/step - accuracy: 0.9415 - loss: 0.1917 - val_accuracy: 0.7110 - val_loss: 1.1837 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 822ms/step - accuracy: 0.9408 - loss: 0.1731 - val_accuracy: 0.7282 - val_loss: 1.0972 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 821ms/step - accuracy: 0.9453 - loss: 0.1723 - val_accuracy: 0.7267 - val_loss: 1.0999 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 825ms/step - accuracy: 0.9528 - loss: 0.1481 - val_accuracy: 0.7140 - val_loss: 1.1057 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 844ms/step - accuracy: 0.9536 - loss: 0.1392 - val_accuracy: 0.7252 - val_loss: 1.0193 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 827ms/step - accuracy: 0.9539 - loss: 0.1482 - val_accuracy: 0.7498 - val_loss: 0.9743 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 822ms/step - accuracy: 0.9541 - loss: 0.1435 - val_accuracy: 0.7491 - val_loss: 0.9512 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 830ms/step - accuracy: 0.9539 - loss: 0.1474 - val_accuracy: 0.7453 - val_loss: 0.9542 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 823ms/step - accuracy: 0.9653 - loss: 0.1165 - val_accuracy: 0.7513 - val_loss: 0.9241 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 825ms/step - accuracy: 0.9620 - loss: 0.1145 - val_accuracy: 0.7543 - val_loss: 0.9604 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 810ms/step - accuracy: 0.9609 - loss: 0.1191 - val_accuracy: 0.7386 - val_loss: 0.9949 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654ms/step - accuracy: 0.9613 - loss: 0.1186\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 812ms/step - accuracy: 0.9613 - loss: 0.1187 - val_accuracy: 0.7662 - val_loss: 0.9403 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 810ms/step - accuracy: 0.9687 - loss: 0.0983 - val_accuracy: 0.7565 - val_loss: 0.9005 - learning_rate: 5.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 809ms/step - accuracy: 0.9699 - loss: 0.0909 - val_accuracy: 0.7483 - val_loss: 0.9352 - learning_rate: 5.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 808ms/step - accuracy: 0.9734 - loss: 0.0933 - val_accuracy: 0.7670 - val_loss: 0.9270 - learning_rate: 5.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 806ms/step - accuracy: 0.9701 - loss: 0.0917 - val_accuracy: 0.7647 - val_loss: 0.8553 - learning_rate: 5.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 815ms/step - accuracy: 0.9717 - loss: 0.0863 - val_accuracy: 0.7737 - val_loss: 0.9390 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fd85001d910>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_incremental_filename(base_name, extension):\n",
        "    counter = 1\n",
        "    while True:\n",
        "        filename = f\"{base_name}_{counter}.{extension}\"\n",
        "        if not os.path.exists(filename):\n",
        "            return filename\n",
        "        counter += 1"
      ],
      "metadata": {
        "id": "XH7sytkZ1shK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "filename = get_incremental_filename(\"my_model\", \"h5\")\n",
        "model.save(filename)\n",
        "\n",
        "model.save(f\"/content/drive/MyDrive/Colab Notebooks/{filename}\")\n",
        "print(f\"Model saved as {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skRiBLdgxI5W",
        "outputId": "76125d62-906e-4f69-b7b2-59bd5648db1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as my_model_2.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Prevent crash on corrupted images\n",
        "\n",
        "def load_model_weights(model_path, weights=None):\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def decode_img(img_path, img_height, img_width):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [img_height, img_width])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def get_images_labels(df, classes, img_height, img_width):\n",
        "    class_list = sorted(list(classes))\n",
        "    label_map = {label: idx for idx, label in enumerate(class_list)}\n",
        "\n",
        "    image_tensors = []\n",
        "    label_tensors = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        img_path = row[\"image_path\"]\n",
        "        label = row[\"label\"]\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Warning: File not found: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img = decode_img(img_path, img_height, img_width)\n",
        "            one_hot = tf.keras.utils.to_categorical(\n",
        "                label_map[label], num_classes=len(classes)\n",
        "            )\n",
        "            image_tensors.append(img)\n",
        "            label_tensors.append(one_hot)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {img_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if not image_tensors or not label_tensors:\n",
        "        print(\"ERROR: No valid test images loaded!\")\n",
        "        return None, None\n",
        "\n",
        "    test_images = tf.stack(image_tensors)\n",
        "    test_labels = tf.convert_to_tensor(label_tensors)\n",
        "    return test_images, test_labels\n",
        "\n",
        "# Define paths directly since argparse doesn't work well in Colab\n",
        "model_path = \"/content/my_model_2.h5\"\n",
        "test_csv_path = \"/content/drive/MyDrive/Colab Notebooks/sample_test_data/mushrooms_test.csv\"\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "classes = {\n",
        "    \"Agaricus\",\n",
        "    \"Amanita\",\n",
        "    \"Boletus\",\n",
        "    \"Cortinarius\",\n",
        "    \"Entoloma\",\n",
        "    \"Hygrocybe\",\n",
        "    \"Lactarius\",\n",
        "    \"Russula\",\n",
        "    \"Suillus\",\n",
        "}\n",
        "\n",
        "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
        "print(\"Loading test images and labels...\")\n",
        "test_images, test_labels = get_images_labels(\n",
        "    test_df, classes, IMG_HEIGHT, IMG_WIDTH\n",
        ")\n",
        "\n",
        "if test_images is None or test_labels is None:\n",
        "    print(\"Exiting due to missing or invalid test data.\")\n",
        "else:\n",
        "    print(\"Loading model...\")\n",
        "    my_model = load_model_weights(model_path)\n",
        "\n",
        "    print(\"Evaluating model...\")\n",
        "    loss, acc = my_model.evaluate(test_images, test_labels, verbose=2)\n",
        "    print(\"Test model accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "5fNhUCwB17HU",
        "outputId": "ba694c39-5f02-445f-982b-722a731330ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test images and labels...\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m655,872\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │         \u001b[38;5;34m2,313\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,313</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,050,571\u001b[0m (11.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,050,571</span> (11.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,959,433\u001b[0m (11.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,959,433</span> (11.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m91,136\u001b[0m (356.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,136</span> (356.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 4036 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7fd86893bb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 4s - 4s/step - accuracy: 1.0000 - loss: 0.1654\n",
            "Test model accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage after training:\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "umpOjJbepGal",
        "outputId": "7d590591-bf60-4a33-e534-117c0ff1ee5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-609a1ae61faf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Example usage after training:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mplot_training_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oB8n2sxZnX3w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}